{
  "hash": "0203f8b6622ae667c169d101a31fff52",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: Fit Analyses\ndescription: Getting, plotting and analyzing parameter recoveries from censoring and truncation simulations.\nauthor:\n  - name: Jeroen E. Timmerman\n    corresponding: true\n    orcid: 0009-0003-8208-0509\n    email: j.e.timmerman@uva.nl\n    affiliations:\n      - name: University of Amsterdam\n        department: Department of Psychology\n        address: Nieuwe Achtergracht 129-B\n        city: Amsterdam\n        region: North-Holland\n        postal-code: 1018 WS\n---\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nlibrary(EMC2)\nlibrary(stringr)\nlibrary(ggplot2)\nlibrary(dplyr)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'dplyr'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n```\n\n\n:::\n\n```{.r .cell-code .hidden}\nlibrary(BayesFactor)\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: package 'BayesFactor' was built under R version 4.4.2\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: coda\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nLoading required package: Matrix\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n************\nWelcome to BayesFactor 0.9.12-4.7. If you have questions, please contact Richard Morey (richarddmorey@gmail.com).\n\nType BFManual() to open the manual.\n************\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\n\nAttaching package: 'BayesFactor'\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nThe following object is masked from 'package:EMC2':\n\n    compare\n```\n\n\n:::\n:::\n\n\n\n# Upper Censoring\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nparsLBA <- c(log(2),3,1,log(2),log(.75),log(.2))\nnames(parsLBA) <- c(\"B\", \"v\", \"v_lMd\", \"A\", \"sv_lMd\", \"t0\")\nparsRDM <- c(log(3),1,.4,log(.75),log(.2))\nnames(parsRDM) <- c(\"B\", \"v\", \"v_lMd\", \"s_lMd\", \"t0\")\nparsLNR <- c(log(.75),log(.65),log(.5),log(.8),log(.4))\nnames(parsLNR) <- c(\"m\", \"m_lMd\", \"s\", \"s_lMd\", \"t0\")\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nfile_names <- list.files(\"../01_simulation/upper_censoring/EMCs\")\nEMCs <- data.frame()\nfor (i in file_names){\n  load(paste0(\"../01_simulation/upper_censoring/EMCs/\", i))\n  EMC <- data.frame(EMC = str_remove(i, \".RData\"),\n                    censoring = str_detect(i, \"sM\"),\n                    model_name = str_extract(i, \"LBA|LNR|RDM\"),\n                    percentage = str_extract(i, \"70|90|975\")\n                    )\n  EMCs <- rbind(EMCs, EMC)\n}\nEMCs <- na.omit(EMCs) # to remove empty sLBA\nEMCs$censoring <- factor(EMCs$censoring, c(FALSE, TRUE), c(\"Truncated\", \"Censored\"))\nEMCs$model_name <- factor(EMCs$model_name)\nEMCs$percentage <- factor(EMCs$percentage, c(975, 90, 70), c(\"2.5%\", \"10%\", \"30%\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\npars <- list()\nfor (i in 1:nrow(EMCs)) {\n  pars[[EMCs$EMC[i]]] <- apply(parameters(get(EMCs$EMC[i], envir = globalenv()), selection = \"alpha\")[,-1], 2, function(x) quantile(x, c(0.025, 0.5, 0.975)))\n  EMCs$RMSE[i] <- sqrt(mean((pars[[EMCs$EMC[i]]][2,] - get(paste0(\"pars\", EMCs$model_name[i]), envir = globalenv()))^2))\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nfrequentist <- t.test(RMSE ~ censoring, data = EMCs)\nfrequentist\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\n\tWelch Two Sample t-test\n\ndata:  RMSE by censoring\nt = 4.4212, df = 9.1973, p-value = 0.001583\nalternative hypothesis: true difference in means between group Truncated and group Censored is not equal to 0\n95 percent confidence interval:\n 0.359907 1.109093\nsample estimates:\nmean in group Truncated  mean in group Censored \n              0.8440147               0.1095145 \n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nmodel <- ttestBF(formula = RMSE ~ censoring, data = EMCs)\nmodel\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nBayes factor analysis\n--------------\n[1] Alt., r=0.707 : 58.5073 Â±0%\n\nAgainst denominator:\n  Null, mu1-mu2 = 0 \n---\nBayes factor type: BFindepSample, JZS\n```\n\n\n:::\n:::\n\n::: {#cell-fig-RMSD_upper .cell apa-note='For each model and each level of data missing, the RMSE was computed.'}\n\n```{.r .cell-code .hidden}\n#| label: fig-RMSD_upper\n#| fig-cap: Root Mean Squared Errors for Upper Censoring in Race Models\n#| apa-note: For each model and each level of data missing, the RMSE was computed.\n\nggplot(EMCs, aes(censoring, RMSE, fill = interaction(percentage, censoring, sep = \" \"))) +\n  facet_grid(~ model_name) +\n  scale_fill_brewer(palette = \"PuOr\") +\n  geom_bar(position = \"dodge\", stat = \"identity\") +\n  labs(fill = \"Missing\")\n```\n\n::: {.cell-output-display}\n![Root Mean Squared Errors for Upper Censoring in Race Models](fit-analyses_files/figure-html/fig-RMSD_upper-1.png){#fig-RMSD_upper width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nparameters_CI <- as.data.frame(t(data.frame(pars)))\nfor (i in 1:nrow(parameters_CI)) {\n  name <- row.names(parameters_CI)[i]\n  parameters_CI$censored[i] <- str_detect(name, \"sM\")\n  parameters_CI$model_name[i] <- str_extract(name, \"LBA|LNR|RDM\")\n  parameters_CI$percentage[i] <- str_extract(name, \"70|90|975\")\n  parameters_CI$parameter[i] <- sub(\".*\\\\.\", \"\", name)\n  parameters_CI$true_parameter[i] <- \n    get(paste0(\"pars\", parameters_CI$model_name[i]), envir = globalenv())[parameters_CI$parameter[i]]\n}\n\nparameters_CI$percentage <- factor(parameters_CI$percentage, c(975, 90, 70), c(\"2.5%\", \"10%\", \"30%\"))\nparameters_CI$censored <- factor(parameters_CI$censored, c(TRUE, FALSE), c(\"Censored\", \"Truncated\"))\n```\n:::\n\n::: {.cell apa-note='Race model recoveries separated by model (LBA, LNR and RDM) and censoring vs truncation. Especially the LBA and LNR parameters are on the identity line for censoring, but off the line for truncation. '}\n\n```{.r .cell-code .hidden}\n#| label: upper_censoring_recoveries\n#| fig-cap: \"Upper Censored / Truncated Recoveries at Different Levels\"\n#| fig-alt: \"\"\n#| apa-note: \"Race model recoveries separated by model (LBA, LNR and RDM) and censoring vs truncation. Especially the LBA and LNR parameters are on the identity line for censoring, but off the line for truncation. \"\n\n# Use recovery.emc {EMC2} to plot recoveries of a single EMC fit\nggplot(parameters_CI, aes(true_parameter, `50%`, color = percentage)) +\n  geom_point() +\n  geom_abline() +\n  geom_errorbar(aes(ymin = `2.5%`, ymax = `97.5%`)) +\n  facet_grid(censored ~ model_name, scales = \"free_y\") +\n  # scale_color_brewer(palette = \"YlOrRd\") +\n  ylab(\"Estimated Parameters\") +\n  xlab(\"True Parameters\")\n```\n\n::: {.cell-output-display}\n![Upper Censored / Truncated Recoveries at Different Levels](fit-analyses_files/figure-html/upper_censoring_recoveries-1.png){width=672}\n:::\n:::\n\n\n\n# Censoring Both\n\n\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nfile_names <- list.files(\"../01_simulation/censoring_both/EMCs\")\nEMCs <- data.frame()\nfor (i in file_names){\n  load(paste0(\"../01_simulation/censoring_both/EMCs/\", i))\n  EMC <- data.frame(EMC = str_remove(i, \".RData\"),\n                    censoring = str_detect(i, \"sM\"),\n                    model_name = str_extract(i, \"LBA|LNR|RDM\"),\n                    tail = str_extract(i, \"lower|upper|both\"),\n                    percentage = str_extract(i, \"2|10|30|50\"),\n                    response_known = !str_detect(i, \"unknown\")\n                    )\n  assign(EMC$EMC, s)\n  EMCs <- rbind(EMCs, EMC)\n}\n\nEMCs$censoring <- factor(EMCs$censoring, c(FALSE, TRUE),\n                         c(\"Truncated\", \"Censored\"))\nEMCs$model_name <- factor(EMCs$model_name)\nEMCs$response_known <- factor(EMCs$response_known, c(FALSE, TRUE),\n                              c(\"unknown\", \"known\"))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nEMCs_expanded <- data.frame()\n\nfor (i in 1:nrow(EMCs)) {\n  # Retrieve the EMC object for the current row\n  emc_data <- get(EMCs$EMC[i], envir = globalenv())\n  \n  # Extract parameter data (excluding the first column which represents subjects)\n  parameter_data <- parameters(emc_data, selection = \"alpha\")[, -1]\n  subject_ids <- parameters(emc_data, selection = \"alpha\")[, 1]  # Subject column\n  \n  # Get the list of parameter names\n  parameter_names <- colnames(parameter_data)\n  \n  # Split data by subject\n  split_data <- split(parameter_data, subject_ids)\n  \n  # Compute quantiles and add rows per parameter and subject\n  for (subject in names(split_data)) {\n    subject_data <- split_data[[subject]]\n    \n    # Compute quantiles for each parameter\n    subject_quantiles <- apply(subject_data, 2, function(x) quantile(x, c(0.25, 0.5, 0.75), na.rm = T))\n    \n    # Add a row for each parameter\n    for (param in parameter_names) {\n      EMCs_expanded <- rbind(EMCs_expanded, data.frame(\n        EMC = EMCs$EMC[i],\n        model_name = EMCs$model_name[i],\n        censoring = EMCs$censoring[i],\n        tail = EMCs$tail[i],\n        percentage = EMCs$percentage[i],\n        response_known = EMCs$response_known[i],\n        subject = subject,\n        parameter_name = param,\n        q25 = subject_quantiles[1, param],\n        Median = subject_quantiles[2, param],\n        q75 = subject_quantiles[3, param],\n        true_parameter = get(paste0(\"pars\", EMCs$model_name[i]), envir = globalenv())[param]\n      ))\n    }\n  }\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nEMCs_expanded$percentage <- as.numeric(EMCs_expanded$percentage)\nEMCs_expanded %>%\n  ggplot(aes(true_parameter, Median, color = subject)) +\n  geom_point(size = 0.1) +\n  geom_abline() +\n  facet_grid(tail + percentage ~ model_name + censoring, scales = \"free_y\") +\n  geom_errorbar(aes(ymin = q25, ymax = q75))\n```\n\n::: {.cell-output .cell-output-stderr .hidden}\n\n```\nWarning: Removed 9 rows containing missing values or values outside the scale range\n(`geom_point()`).\n```\n\n\n:::\n\n::: {.cell-output-display}\n![](fit-analyses_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbetween(parsLBA, EMCs_expanded$q25[EMCs_expanded$EMC == \"sMLBAlower2known\"][1:6], EMCs_expanded$q75[EMCs_expanded$EMC == \"sMLBAlower2known\"][1:6])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  TRUE FALSE FALSE FALSE  TRUE  TRUE\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\n# Calculate RMSE per group\nEMCs_RMSEs <- EMCs_expanded %>%\n  group_by(subject, EMC, percentage, response_known, \n           tail, censoring, model_name) %>%\n  summarise(\n    RMSE = sqrt(mean((Median - true_parameter)^2)),  # Calculate RMSE\n    .groups = 'drop'  # Ungroup after summarizing\n  )\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code .hidden}\nbig_model <- aov(RMSE ~ percentage * response_known *\n           tail * censoring * model_name, data = EMCs_RMSEs)\n\nsummary(big_model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n                                                      Df Sum Sq Mean Sq F value\npercentage                                             1  39.74   39.74 786.596\nresponse_known                                         1   0.26    0.26   5.058\ntail                                                   2   7.63    3.81  75.479\ncensoring                                              1  18.08   18.08 357.993\nmodel_name                                             2  81.76   40.88 809.211\npercentage:response_known                              1   0.33    0.33   6.611\npercentage:tail                                        2   0.38    0.19   3.737\nresponse_known:tail                                    2   0.46    0.23   4.575\npercentage:censoring                                   1   1.50    1.50  29.694\nresponse_known:censoring                               1   0.43    0.43   8.511\ntail:censoring                                         2  13.31    6.66 131.753\npercentage:model_name                                  2  15.96    7.98 157.956\nresponse_known:model_name                              2   1.62    0.81  16.070\ntail:model_name                                        4   6.78    1.69  33.530\ncensoring:model_name                                   2   0.21    0.11   2.118\npercentage:response_known:tail                         2   0.66    0.33   6.533\npercentage:response_known:censoring                    1   0.56    0.56  11.016\npercentage:tail:censoring                              2   4.01    2.00  39.686\nresponse_known:tail:censoring                          2   0.28    0.14   2.723\npercentage:response_known:model_name                   2   1.68    0.84  16.670\npercentage:tail:model_name                             4   2.21    0.55  10.939\nresponse_known:tail:model_name                         4   1.26    0.32   6.258\npercentage:censoring:model_name                        2   3.13    1.57  31.012\nresponse_known:censoring:model_name                    2   1.67    0.83  16.480\ntail:censoring:model_name                              4  14.23    3.56  70.406\npercentage:response_known:tail:censoring               2   0.71    0.35   7.014\npercentage:response_known:tail:model_name              4   1.39    0.35   6.873\npercentage:response_known:censoring:model_name         2   1.93    0.96  19.068\npercentage:tail:censoring:model_name                   4   4.75    1.19  23.504\nresponse_known:tail:censoring:model_name               4   0.94    0.23   4.650\npercentage:response_known:tail:censoring:model_name    4   1.67    0.42   8.265\nResiduals                                           1359  68.65    0.05        \n                                                      Pr(>F)    \npercentage                                           < 2e-16 ***\nresponse_known                                      0.024668 *  \ntail                                                 < 2e-16 ***\ncensoring                                            < 2e-16 ***\nmodel_name                                           < 2e-16 ***\npercentage:response_known                           0.010243 *  \npercentage:tail                                     0.024073 *  \nresponse_known:tail                                 0.010468 *  \npercentage:censoring                                6.00e-08 ***\nresponse_known:censoring                            0.003588 ** \ntail:censoring                                       < 2e-16 ***\npercentage:model_name                                < 2e-16 ***\nresponse_known:model_name                           1.26e-07 ***\ntail:model_name                                      < 2e-16 ***\ncensoring:model_name                                0.120615    \npercentage:response_known:tail                      0.001501 ** \npercentage:response_known:censoring                 0.000927 ***\npercentage:tail:censoring                            < 2e-16 ***\nresponse_known:tail:censoring                       0.066065 .  \npercentage:response_known:model_name                7.04e-08 ***\npercentage:tail:model_name                          9.87e-09 ***\nresponse_known:tail:model_name                      5.46e-05 ***\npercentage:censoring:model_name                     6.76e-14 ***\nresponse_known:censoring:model_name                 8.48e-08 ***\ntail:censoring:model_name                            < 2e-16 ***\npercentage:response_known:tail:censoring            0.000932 ***\npercentage:response_known:tail:model_name           1.78e-05 ***\npercentage:response_known:censoring:model_name      6.81e-09 ***\npercentage:tail:censoring:model_name                 < 2e-16 ***\nresponse_known:tail:censoring:model_name            0.000990 ***\npercentage:response_known:tail:censoring:model_name 1.38e-06 ***\nResiduals                                                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n9 observations deleted due to missingness\n```\n\n\n:::\n:::\n\n::: {#cell-fig-RMSD_both .cell apa-note='For each model, the RMSE was computed over all subject fits.'}\n\n```{.r .cell-code .hidden}\n#| label: fig-RMSD_both\n#| fig-cap: Root Mean Squared Errors in each condition\n#| apa-note: For each model, the RMSE was computed over all subject fits.\n\nna.omit(EMCs_RMSEs) %>%\n  ggplot(aes(censoring, RMSE, fill = interaction(percentage, censoring, sep = \"% \"))) +\n  facet_grid(tail + response_known ~ model_name) +\n  scale_fill_brewer(palette = \"PuOr\") +\n  stat_summary(position = \"dodge\", geom = \"bar\", fun = \"mean\") +\n  labs(fill = \"Missing\")\n```\n\n::: {.cell-output-display}\n![Root Mean Squared Errors in each condition](fit-analyses_files/figure-html/fig-RMSD_both-1.png){#fig-RMSD_both width=672}\n:::\n:::\n",
    "supporting": [
      "fit-analyses_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}